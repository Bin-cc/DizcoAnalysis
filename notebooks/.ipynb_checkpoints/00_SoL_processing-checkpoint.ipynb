{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07958350-c85d-4128-a7df-d4646f0631ad",
   "metadata": {},
   "source": [
    "###### 本代码为dizco的python复现版本\r\n",
    "##### #原始代码用R书写（https://github.com/jmwozniak/DizcoProcessing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aed21d-fb41-4d0e-a10f-535e0748f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve,mean_squared_error,log_loss\n",
    "import datetime\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e622e-3290-4b4c-a995-1ed2c6ddbdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#判断肽段修饰中是否包含目标修饰\n",
    "def label_match(values,modID,col_mod):\n",
    "    try:\n",
    "        if np.isnan(values[col_mod+1]): return np.nan\n",
    "    except:\n",
    "        mod = values[col_mod+1].split('; ')\n",
    "        match = [m for m in mod if any(name in m for name in modID)]\n",
    "        return values[0] if match != [] else np.nan\n",
    "\n",
    "#判断值是否为空，若是则返回True，反之则为False\n",
    "def is_not_nan(value):\n",
    "    return True if not np.isnan(value) else False\n",
    "\n",
    "#提取modID中所提及的修饰的肽段\n",
    "def extract_labeled(data,modID,col_mod):\n",
    "    data = data.reset_index(drop=False)\n",
    "    index = list(map(lambda x:label_match(x,modID,col_mod), data.values))\n",
    "    index = list(filter(lambda x:is_not_nan(x), index))\n",
    "    return data.iloc[index,1:].reset_index(drop=True)\n",
    "\n",
    "#提取Master Protein Accessions的ID，保留第一个ID或所有ID\n",
    "def id_extrac(values,col_num,uni):\n",
    "    if uni: return values[col_num].split('; ')[0]\n",
    "    else: return values[col_num]\n",
    "\n",
    "#提取Master Protein Accessions的ID\n",
    "def extract_proteins(data,col_num,uni=True):\n",
    "    prot_ids = list(map(lambda x:id_extrac(x,col_num,uni), data.values))\n",
    "    return prot_ids\n",
    "\n",
    "#去除修饰中modName所列出来的修饰，剩余的修饰中仅保留修饰的氨基酸及其位点\n",
    "def removed_mod(mod,modName):\n",
    "    try:\n",
    "        if np.isnan(mod): return mod\n",
    "    except:\n",
    "        mod = mod.split('; ')\n",
    "        match = [m.split('(')[0] for m in mod if not any(name in m for name in modName)]\n",
    "        if match == []: return np.nan\n",
    "        return ';'.join(match)\n",
    "\n",
    "#分别提取修饰的氨基酸及其位点\n",
    "def extract_aa_site(mod,aa=False,site=False):\n",
    "    try:\n",
    "        if np.isnan(mod): return mod\n",
    "    except:\n",
    "        aa_lt = ';'.join([m[0] for m in mod])\n",
    "        site_lt = ';'.join([m[1:] for m in mod])\n",
    "        if aa: return aa_lt\n",
    "        if site: return site_lt\n",
    "\n",
    "#根据给定的table计算每个蛋白的PSM\n",
    "def cal_prot_psm(input_table,merge_table,col_name):\n",
    "    total_psm = input_table.groupby(by=['Master Protein Accessions']).count().reset_index(drop=False).iloc[:,:2]\n",
    "    total_psm.columns = ['Master Protein Accessions',col_name]\n",
    "    merge_table = pd.merge(merge_table, total_psm,how='outer')\n",
    "    return merge_table\n",
    "\n",
    "#根据给定的table计算每个蛋白的unique peptide数量\n",
    "def cal_uni_pep(input_table,merge_table,col_name):\n",
    "    uni_pep_num = []\n",
    "    for prot,table in input_table.groupby(by=['Master Protein Accessions']):\n",
    "        num = len(table['Upper_Seq'].unique())\n",
    "        uni_pep_num.append(tuple((prot,num)))\n",
    "    uni_pep_num = pd.DataFrame(uni_pep_num,columns=['Master Protein Accessions',col_name])\n",
    "    merge_table = pd.merge(merge_table, uni_pep_num,how='outer')\n",
    "    return merge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986916b0-edec-49a1-a0b2-f6142fdfd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对同位素标记的PSM数据进行处理，并进行训练\n",
    "#处理过程包括以下步骤：\n",
    "#1. 获取唯一的Uniprot ID以及质谱打到的肽段\n",
    "#2. 提取含有modID修饰的肽段信息，即标记氨基酸及其位点\n",
    "#3. 基于First Scan和File ID信息生成相应的肽段ID，用于后续的PSM计算\n",
    "#4. 根据肽段是否有modID的修饰，将数据拆分为labeled_psms和unlabeled_psms，对labeled_psms会进一步依据其轻标或重标修饰，进行拆分\n",
    "#5. 提取对于同时在轻标和重标出现的肽段，并在pair列将其标记为1\n",
    "#6. 根据此前生成的肽段ID信息，统计肽段的PSM，scoreDiff，并进行标准化得到numPSMs_scaled，scoreDiff_scaled\n",
    "#   此外还计算了agreePSMs，它是肽段的一致性比例，也即它在多个质谱文件中出现的频率\n",
    "#7. 统计labeled_psms与unlabeled_psms在不同肽段长度的平均保留时间\n",
    "#   并用未被标记的不同长度的肽段的平均保留时间与肽段本身的保留时间求它们之间的差值，并标准化得RT_Diff_fromUPL_scaled\n",
    "#8. 统计蛋白的PSM以及unique peptides数量\n",
    "#9. 生成训练集与测试集，其中阳性样本在训练集和测试集中分别为paired为1和0的肽段\n",
    "#   阴性样本来源于unlabeled_psms，且按照1:1的比例分配给训练集与测试集\n",
    "#10. 使用上述的numPSMs_scaled，scoreDiff_scaled，agreePSMs，RT_Diff_fromUPL_scaled结合逻辑回归训练并预测标记肽段\n",
    "def processPSMs_isotope(data,modID,ptmRS=True):\n",
    "    if ptmRS: use_col = [1,3,4,5,7,8,9,10,11,12,15,16,17,18,19,24,25,26,27,28,32]\n",
    "    else: use_col = [1,3,4,5]+list(range(7,13))+list(range(15,20))+list(range(24,29))\n",
    "    data = data.iloc[:,use_col]\n",
    "    \n",
    "    #1. 获取唯一的Uniprot ID以及质谱打到的肽段\n",
    "    data['Master Protein Accessions'][data['Master Protein Accessions'].isna()] = data['Protein Accessions'][data['Master Protein Accessions'].isna()]\n",
    "    data['Master Protein Accessions'] = extract_proteins(data,col_num=4,uni=True)\n",
    "    data['Upper_Seq'] = data['Annotated Sequence'].str.split('.',expand=True)[1].str.upper()\n",
    "    \n",
    "    #2. 提取含有modID标记的肽段信息，即标记氨基酸及其位点\n",
    "    modName = ['Oxidation','Carbamidomethyl']\n",
    "    data['label_site'] = list(map(lambda x:removed_mod(x,modName), data['Modifications'].to_list()))\n",
    "    data['label_AA'] = list(map(lambda x:extract_aa_site(x,aa=True), data['label_site'].str.split(';')))\n",
    "    data['label_loc'] = list(map(lambda x:extract_aa_site(x,site=True), data['label_site'].str.split(';')))\n",
    "    \n",
    "    #3. 基于First Scan和File ID信息生成相应的肽段ID，用于后续的PSM计算\n",
    "    data['scanID'] = data['First Scan'].map(str).str.cat([data['File ID']],sep='_')\n",
    "    data['scanID_pep'] = data['scanID'].map(str).str.cat([data['Annotated Sequence'].str.upper()],sep='_')\n",
    "    data['uniqueID'] = data['scanID_pep'].map(str).str.cat([data['Modifications'].replace(np.nan,'-')],sep='_').str.strip('-')\n",
    "    data['pepLength'] = list(map(lambda x:len(x), data['Upper_Seq'].to_list()))\n",
    "    \n",
    "    #4. 根据肽段是否有modID的修饰，以及具体的轻标或重标修饰，将数据拆分为labeled_psms和unlabeled_psms\n",
    "    labeled_psms = extract_labeled(data,modID,3)\n",
    "    labeled_psms['labeled'] = 1\n",
    "    data = pd.merge(data, labeled_psms,how='outer')\n",
    "    data['labeled'] = data['labeled'].replace(np.nan,0)\n",
    "    unlabeled_psms = data[data['labeled']==0].reset_index(drop=True)\n",
    "    unlabeled_psms['paired'] = 0\n",
    "    light_mod,heavy_mod = modID[0],modID[1]\n",
    "    light_psms = extract_labeled(labeled_psms,[light_mod],3)\n",
    "    heavy_psms = extract_labeled(labeled_psms,[heavy_mod],3)\n",
    "    \n",
    "    #5. 提取对于同时在轻标和重标出现的肽段，并在pair列将其标记为1\n",
    "    data.loc[data['scanID'].isin(heavy_psms['scanID']),'label_type'] = 'H'\n",
    "    data.loc[data['scanID'].isin(light_psms['scanID']),'label_type'] = 'L'\n",
    "    data['label_type'] = data['label_type'].replace(np.nan,'NA')\n",
    "    labeled_psms.loc[(labeled_psms['Upper_Seq'].isin(heavy_psms['Upper_Seq']))&(labeled_psms['Upper_Seq'].isin(light_psms['Upper_Seq'])),'paired'] = 1\n",
    "    labeled_psms['paired'] = labeled_psms['paired'].replace(np.nan,0)\n",
    "    paired_psms = labeled_psms[labeled_psms['paired']==1].reset_index(drop=True)\n",
    "    data = pd.merge(data, paired_psms,how='outer')\n",
    "    data['paired'] = data['paired'].replace(np.nan,0)\n",
    "    \n",
    "    #6. 根据此前生成的肽段ID信息，统计肽段的PSM，scoreDiff，并进行标准化得到numPSMs_scaled，scoreDiff_scaled\n",
    "    #此外还计算了agreePSMs，它是肽段的一致性比例，也即它在多个质谱文件中出现的频率\n",
    "    scan_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(data['scanID']).items()],columns=['scanID','numPSMs'])\n",
    "    data = pd.merge(data, scan_freq,how='outer')\n",
    "    data['numPSMs_scaled'] = StandardScaler().fit_transform(data['numPSMs'].values.reshape(len(data),1))\n",
    "    scan_psm_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(data['scanID_pep']).items()],columns=['scanID_pep','agreePSMs'])\n",
    "    data = pd.merge(data, scan_psm_freq,how='outer')\n",
    "    data['agreePSMs'] = data['agreePSMs']/data['numPSMs']\n",
    "    data['scoreDiff'] = [data.loc[i,'Delta Score'] if not pd.isna(data.loc[i,'Delta Score'])\n",
    "                         else data.loc[i,'Delta Cn'] for i in data.index]\n",
    "    data['scoreDiff_scaled'] = StandardScaler().fit_transform(data['scoreDiff'].values.reshape(len(data),1))\n",
    "    \n",
    "    #7. 统计labeled_psms与unlabeled_psms在不同肽段长度的平均保留时间\n",
    "    #并用未被标记的不同长度的肽段的平均保留时间与肽段本身的保留时间求它们之间的差值，并标准化得RT_Diff_fromUPL_scaled\n",
    "    RT_mat = pd.DataFrame()\n",
    "    RT_mat['pepLength'] = data['pepLength'].unique()\n",
    "    upl = unlabeled_psms.groupby(by=['pepLength']).mean()['RT in min'].reset_index(drop=False)\n",
    "    upl.columns = ['pepLength','RTavg_fromUPL']\n",
    "    RT_mat = pd.merge(RT_mat, upl,how='outer')\n",
    "    lpl = paired_psms.groupby(by=['pepLength']).mean()['RT in min'].reset_index(drop=False)\n",
    "    lpl.columns = ['pepLength','RTavg_fromLPL']\n",
    "    RT_mat = pd.merge(RT_mat, lpl,how='outer')\n",
    "    data = pd.merge(data, RT_mat,how='outer')\n",
    "    data['RT_Diff_fromUPL'] = data['RTavg_fromUPL']-data['RT in min']\n",
    "    data['RT_Diff_fromUPL_scaled'] = StandardScaler().fit_transform(data['RT_Diff_fromUPL'].values.reshape(len(data),1))\n",
    "    \n",
    "    #8. 统计蛋白的PSM以及unique peptides数量\n",
    "    data['ProtID_Pep'] = data['Master Protein Accessions'].map(str).str.cat([data['Upper_Seq']],sep='_')\n",
    "    data = cal_prot_psm(data,data,'Prot_totalPSMs')\n",
    "    data = cal_prot_psm(labeled_psms,data,'Prot_labeledPSMs')\n",
    "    data = cal_prot_psm(paired_psms,data,'Prot_pairedPSMs')\n",
    "    data = cal_uni_pep(data,data,'Prot_uniquePeptides')\n",
    "    data = cal_uni_pep(labeled_psms,data,'Prot_labeledPeptides')\n",
    "    data = cal_uni_pep(paired_psms,data,'Prot_pairedPeptides')\n",
    "    \n",
    "    #9. 生成训练集与测试集，其中阳性样本在训练集和测试集中分别为paired为1和0的肽段\n",
    "    #阴性样本来源于unlabeled_psms，且按照1:1的比例分配给训练集与测试集\n",
    "    data = data[~data['RT_Diff_fromUPL'].isna()].reset_index(drop=True) #这一步是为了避免由于RT_Diff_fromUPL存在缺失值引起的训练错误\n",
    "    trainNegative = unlabeled_psms.iloc[0::2,:]\n",
    "    testNegative = unlabeled_psms.iloc[1::2,:]\n",
    "    trainSet = pd.concat([data[data['paired']==1],\n",
    "                          data[data['uniqueID'].isin(trainNegative['uniqueID'].to_list())]],axis=0).reset_index(drop=True)\n",
    "    testSet = pd.concat([data[(data['paired']==0)&(data['labeled']==1)],\n",
    "                          data[data['uniqueID'].isin(testNegative['uniqueID'].to_list())]],axis=0).reset_index(drop=True)\n",
    "    \n",
    "    #10. 使用上述的numPSMs_scaled，scoreDiff_scaled，agreePSMs，RT_Diff_fromUPL_scaled结合逻辑回归训练并预测标记肽段\n",
    "    use_name = ['numPSMs_scaled','scoreDiff_scaled','agreePSMs','RT_Diff_fromUPL_scaled']\n",
    "    lg_clf = LogisticRegression(solver='lbfgs',penalty='none',n_jobs=-1)\n",
    "    X = trainSet[use_name].values.astype(np.float64)\n",
    "    y = trainSet['labeled'].values.astype(np.float64)\n",
    "    lg_clf = lg_clf.fit(X,y)\n",
    "    \n",
    "    y_pre_train = lg_clf.predict_proba(X)[:,1]\n",
    "    y_pre_test = lg_clf.predict_proba(testSet[use_name].values.astype(np.float64))[:,1]\n",
    "    \n",
    "    train_out = trainSet.copy()\n",
    "    train_out['lg_probs'] = y_pre_train\n",
    "    train_out.loc[train_out['lg_probs']>0.5,'lg_pred'] = 'Labeled'\n",
    "    train_out.loc[train_out['lg_probs']<=0.5,'lg_pred'] = 'Unlabeled'\n",
    "    train_out['model_set'] = 'train'\n",
    "    \n",
    "    test_out = testSet.copy()\n",
    "    test_out['lg_probs'] = y_pre_test\n",
    "    test_out.loc[test_out['lg_probs']>0.5,'lg_pred'] = 'Labeled'\n",
    "    test_out.loc[test_out['lg_probs']<=0.5,'lg_pred'] = 'Unlabeled'\n",
    "    test_out['model_set'] = 'test'\n",
    "    \n",
    "    merge_out = pd.concat([train_out,test_out],axis=0)\n",
    "    merge_out.loc[merge_out['lg_probs']>=0.85,'label_confidence'] = 'High'\n",
    "    merge_out.loc[(merge_out['lg_probs']>=0.5)&(merge_out['lg_probs']<0.85),'label_confidence'] = 'Medium'\n",
    "    merge_out.loc[merge_out['lg_probs']<0.5,'label_confidence'] = 'Low'\n",
    "\n",
    "    return(merge_out.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea939b-92c7-4f19-b53e-72bfe3e6f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对每一个传进来的uni_id，在processedPSMs中找到该uni_id所对应的修饰位点信息\n",
    "def extract_site(uni_id,processedPSMs):\n",
    "    table = processedPSMs[processedPSMs['pep_label']==uni_id].reset_index(drop=True)\n",
    "    all_sites = table['label_site'].to_list()\n",
    "    sites = list(table['label_site'].unique())\n",
    "    locs = list(table['label_loc'].unique())\n",
    "    if table[~table['label_site'].isna()].empty:\n",
    "        return tuple((uni_id,np.nan,np.nan,np.nan,np.nan))\n",
    "    \n",
    "    aas = [site[0] for site in sites]\n",
    "    siteDF = pd.DataFrame(data=[sites,aas,locs]).T\n",
    "    siteDF.columns=['sites','aas','locs']\n",
    "    site_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(all_sites).items()],columns=['sites','site_freq'])\n",
    "    siteDF = pd.merge(siteDF, site_freq,how='outer')\n",
    "    siteDF = siteDF.sort_values(by=['locs'],ascending=True,key=lambda x: pd.to_numeric(x, errors='coerce')).reset_index(drop=True)\n",
    "    siteDF = siteDF.astype(str)\n",
    "    return tuple([uni_id])+tuple([';'.join(siteDF[col].to_list()) for col in siteDF.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25061084-d73f-4b59-9c87-b8315d805024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于同位素的PSM统计数据，在肽段层面上做进一步统计，具体过程如下：\n",
    "#1. 根据光谱和First Scan的信息为每个被探针标记的肽段赋予unique_scanID和pep_label\n",
    "#2. 对每一个unique_scanID选取Prot_totalPSMs或XCorr最高的肽段创建uniqueScan_DF\n",
    "#3. 根据uniqueScan_DF和PSM数据，统计每条标记肽段的光谱数和PSM数\n",
    "#4. 同位素输出的PSM数据，统计每条标记肽段的平均预测分数，XCorr，scoreDiff，numPSMs和RT_Diff_fromUPL\n",
    "#5. 统计每条标记肽段的标记位点，被标记的频率等信息\n",
    "def processPeps_isotope(processedPSMs):\n",
    "    #1. 根据光谱，First Scan和肽段信息为每个被探针标记的肽段赋予unique_scanID和pep_label\n",
    "    processedPSMs['unique_scanID'] = processedPSMs['First Scan'].map(str).str.cat([processedPSMs['Spectrum File']],sep='_')\n",
    "    processedPSMs['probeID'] = processedPSMs['Spectrum File'].str.split('_',expand=True)[3]\n",
    "    processedPSMs.loc[processedPSMs[processedPSMs['labeled']==0].index,['probeID']] = np.nan\n",
    "    processedPSMs['pep_label'] = processedPSMs['Upper_Seq'].map(str).str.cat([processedPSMs['probeID'].replace(np.nan,'-')],sep='_').str.strip('-')\n",
    "    processedPSMs_sorted = processedPSMs.sort_values(by=['unique_scanID','Prot_totalPSMs','XCorr'],ascending=[False,False,False]).reset_index(drop=True)\n",
    "    \n",
    "    #2. 对每一个unique_scanID选取Prot_totalPSMs或XCorr最高的肽段创建uniqueScan_DF\n",
    "    uniqueScan_DF = []\n",
    "    for uni_scan,table in processedPSMs_sorted.groupby(by=['unique_scanID']):\n",
    "        table = table.sort_values(by=['Prot_totalPSMs','XCorr'],ascending=[False,False]).reset_index(drop=True)\n",
    "        uniqueScan_DF.append(table.iloc[0,:].values)\n",
    "    uniqueScan_DF = pd.DataFrame(uniqueScan_DF,columns=processedPSMs_sorted.columns)\n",
    "    uniqueScan_DF['probeID'] = uniqueScan_DF['Spectrum File'].str.split('_',expand=True)[3]\n",
    "    uniqueScan_DF.loc[uniqueScan_DF[uniqueScan_DF['labeled']==0].index,['probeID']] = np.nan\n",
    "    uniqueScan_DF['pep_label'] = uniqueScan_DF['Upper_Seq'].map(str).str.cat([uniqueScan_DF['probeID'].replace(np.nan,'-')],sep='_').str.strip('-')\n",
    "    \n",
    "    #3. 根据uniqueScan_DF和同位素输出的PSM数据，统计每条标记肽段的光谱数和PSM数\n",
    "    pepDF = pd.DataFrame()\n",
    "    pepDF['Unique_ID'] = uniqueScan_DF['pep_label'].unique()\n",
    "    pepDF = pd.merge(pepDF, uniqueScan_DF[['Master Protein Accessions','pep_label']],left_on=['Unique_ID'],right_on=['pep_label'],how='inner').drop_duplicates().iloc[:,:-1]\n",
    "    pepDF.columns = ['Unique_ID','Uniprot_ID']\n",
    "    spec_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(uniqueScan_DF['pep_label']).items()],columns=['Unique_ID','#_Spectra'])\n",
    "    pepDF = pd.merge(pepDF, spec_freq,how='outer')\n",
    "    psm_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(processedPSMs['pep_label']).items()],columns=['Unique_ID','#_PSMs'])\n",
    "    pepDF = pd.merge(pepDF, psm_freq,how='inner')\n",
    "    \n",
    "    #4. 同位素输出的PSM数据，统计每条标记肽段的平均预测分数，XCorr，scoreDiff，numPSMs和RT_Diff_fromUPL\n",
    "    featureCols = ['lg_probs','XCorr','scoreDiff','numPSMs','RT_Diff_fromUPL']\n",
    "    averagedFeatures = processedPSMs.groupby(by='pep_label').mean()[featureCols].reset_index(drop=False)\n",
    "    averagedFeatures.rename(columns={'pep_label':'Unique_ID'},inplace=True)\n",
    "    pepDF = pd.merge(pepDF, averagedFeatures,on='Unique_ID',how='inner')\n",
    "    max_lg = processedPSMs[['pep_label','lg_probs']].groupby(by='pep_label').max().reset_index(drop=False)\n",
    "    max_lg.columns = ['Unique_ID','max_lg_probs']\n",
    "    pepDF = pd.merge(pepDF, max_lg,on='Unique_ID',how='inner')\n",
    "    \n",
    "    #5. 统计每条标记肽段的标记位点，被标记的频率等信息\n",
    "    values = list(map(lambda x:extract_site(x,processedPSMs), pepDF['Unique_ID'].to_list()))\n",
    "    values = pd.DataFrame(values,columns=['Unique_ID','sites','aas','locs','site_psms'])\n",
    "    pepDF = pd.merge(pepDF, values,on='Unique_ID',how='inner')\n",
    "    pepDF['PEPTIDE_SEQUENCE'] = pepDF['Unique_ID'].str.split('_',expand=True)[0]\n",
    "    \n",
    "    return pepDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e1c55-41e7-4396-afb8-67f4ea5758a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算每条肽段中TMT修饰数量\n",
    "def count_tmt(mod):\n",
    "    mod = mod.split('; ')\n",
    "    count = 0\n",
    "    for m in mod:\n",
    "        if 'TMT' in m: count += 1\n",
    "    return str(count)\n",
    "\n",
    "#对TMT的PSM数据进行处理，并使用同位素的PSM数据进行模型训练并预测TMT的结果\n",
    "#处理过程包括以下步骤：\n",
    "#1. 根据需要选择合适的列用于后续的数据统计\n",
    "#2. 提取含有modID修饰的肽段信息，即标记氨基酸及其位点\n",
    "#3. 基于First Scan和File ID信息生成一系列相应的肽段ID，用于后续的PSM计算\n",
    "#4. 去除含有CP266修饰的肽段，随后根据肽段是否有modID的修饰，将数据拆分为labeled_psms和unlabeled_psms\n",
    "#5. 根据此前生成的肽段ID信息，统计肽段的PSM，scoreDiff，并进行标准化得到numPSMs_scaled，scoreDiff_scaled\n",
    "#   此外还计算了agreePSMs，它是肽段的一致性比例，也即它在多个质谱文件中出现的频率\n",
    "#6. 统计labeled_psms与unlabeled_psms在不同肽段长度的平均保留时间\n",
    "#   并用未被标记的不同长度的肽段的平均保留时间与肽段本身的保留时间求它们之间的差值，并标准化得RT_Diff_fromUPL_scaled\n",
    "#7. 统计蛋白的PSM以及unique peptides数量\n",
    "#8. 在处理后的同位素数据选择paired为1或labeled为0的肽段，这样就保证了训练集中的阳性与阴性数据\n",
    "#   随后重新计算RT_Diff_fromUPL_scaled，scoreDiff_scaled和numPSMs_scaled并用于模型训练\n",
    "#9. 用训练好的模型预测TMT的数据\n",
    "#10. 总结训练集与测试集的结果，计算协方差矩阵，最后将测试集结果导出\n",
    "def processPSMs_TMT(data, modID, train_set_forPred, ptmRS=True, plex='10plex', quant_level='MS3'):\n",
    "    \n",
    "    #1. 根据需要选择合适的列用于后续的数据统计\n",
    "    infor_col = [1,3,4,5,7,8,9,10,11,12,15,16,17,18,19,22,24,25,26,27,28,29,40,41]\n",
    "    if plex == '16plex': abund_col = list(range(30,46))\n",
    "    elif plex == '10plex': abund_col = list(range(30,40))\n",
    "    else: print('Invalidated input')\n",
    "    use_col = infor_col+abund_col\n",
    "    if quant_level == 'MS3': use_col.append(23)\n",
    "    if ptmRS: use_col.append(45)\n",
    "    data = data.iloc[:,use_col]\n",
    "    \n",
    "    #2. 提取含有modID修饰的肽段信息，即标记氨基酸及其位点\n",
    "    data['Master Protein Accessions'][data['Master Protein Accessions'].isna()] = data['Protein Accessions'][data['Master Protein Accessions'].isna()]\n",
    "    data['Master Protein Accessions'] = extract_proteins(data,col_num=4,uni=True)\n",
    "    data['Upper_Seq'] = data['Annotated Sequence'].str.split('.',expand=True)[1].str.upper()\n",
    "    modName = ['TMT6plex','TMTpro','Carbamidomethyl','Oxidation']\n",
    "    data['label_site'] = list(map(lambda x:removed_mod(x,modName), data['Modifications'].to_list()))\n",
    "    data['label_AA'] = list(map(lambda x:extract_aa_site(x,aa=True), data['label_site'].str.split(';')))\n",
    "    data['label_loc'] = list(map(lambda x:extract_aa_site(x,site=True), data['label_site'].str.split(';')))\n",
    "    for m in modID: data[m] = ['1' if m in mod else '0' for mod in data['Modifications']]\n",
    "    \n",
    "    #3. 基于First Scan和File ID信息生成一系列相应的肽段ID，用于后续的PSM计算\n",
    "    data['pep_label'] = data[['Upper_Seq']+modID].apply(lambda x: '_'.join(x), axis=1)\n",
    "    data['scanID'] = data['First Scan'].map(str).str.cat([data['File ID']],sep='_')\n",
    "    data['scanID_pep'] = data['scanID'].map(str).str.cat([data['Annotated Sequence'].str.upper()],sep='_')\n",
    "    data['uniqueID'] = data['scanID_pep'].map(str).str.cat([data['Modifications'].replace(np.nan,'-')],sep='_').str.strip('-')\n",
    "    data['pepLength'] = list(map(lambda x:len(x), data['Upper_Seq'].to_list()))\n",
    "    data['numTMT'] = list(map(lambda x:count_tmt(x), data['Modifications'].to_list()))\n",
    "    data['pepLength_numTMT'] = data['pepLength'].map(str).str.cat([data['numTMT']],sep='_')\n",
    "    \n",
    "    #4. 去除含有CP266修饰的肽段，随后根据肽段是否有modID的修饰，将数据拆分为labeled_psms和unlabeled_psms\n",
    "    index = [i for i in data.index if 'CP266' not in data.loc[i,'Modifications']]\n",
    "    data = data.iloc[index,:].reset_index(drop=True)\n",
    "    labeled_psms = extract_labeled(data,modID,3)\n",
    "    labeled_psms['labeled'] = 1\n",
    "    data = pd.merge(data, labeled_psms,how='outer')\n",
    "    data['labeled'] = data['labeled'].replace(np.nan,0)\n",
    "    unlabeled_psms = data[data['labeled']==0].reset_index(drop=True)\n",
    "    \n",
    "    #5. 根据此前生成的肽段ID信息，统计肽段的PSM，scoreDiff，并进行标准化得到numPSMs_scaled，scoreDiff_scaled\n",
    "    #   此外还计算了agreePSMs，它是肽段的一致性比例，也即它在多个质谱文件中出现的频率\n",
    "    scan_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(data['scanID']).items()],columns=['scanID','numPSMs'])\n",
    "    data = pd.merge(data, scan_freq,how='outer')\n",
    "    data['numPSMs_scaled'] = StandardScaler().fit_transform(data['numPSMs'].values.reshape(len(data),1))\n",
    "    scan_psm_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(data['scanID_pep']).items()],columns=['scanID_pep','agreePSMs'])\n",
    "    data = pd.merge(data, scan_psm_freq,how='outer')\n",
    "    data['agreePSMs'] = data['agreePSMs']/data['numPSMs']\n",
    "    data['scoreDiff'] = [data.loc[i,'Delta Score'] if not pd.isna(data.loc[i,'Delta Score'])\n",
    "                         else data.loc[i,'Delta Cn'] for i in data.index]\n",
    "    data['scoreDiff_scaled'] = StandardScaler().fit_transform(data['scoreDiff'].values.reshape(len(data),1))\n",
    "    \n",
    "    #6. 统计labeled_psms与unlabeled_psms在不同肽段长度的平均保留时间\n",
    "    #   并用未被标记的不同长度的肽段的平均保留时间与肽段本身的保留时间求它们之间的差值，并标准化得RT_Diff_fromUPL_scaled\n",
    "    RT_mat = pd.DataFrame()\n",
    "    RT_mat['pepLength_numTMT'] = data['pepLength_numTMT'].unique()\n",
    "    upl = unlabeled_psms.groupby(by=['pepLength_numTMT']).mean()['RT in min'].reset_index(drop=False)\n",
    "    upl.columns = ['pepLength_numTMT','RTavg_fromUPL']\n",
    "    RT_mat = pd.merge(RT_mat, upl,how='outer')\n",
    "    lpl = labeled_psms.groupby(by=['pepLength_numTMT']).mean()['RT in min'].reset_index(drop=False)\n",
    "    lpl.columns = ['pepLength_numTMT','RTavg_fromLPL']\n",
    "    RT_mat = pd.merge(RT_mat, lpl,how='outer')\n",
    "    RT_mat = RT_mat.sort_values(by=['pepLength_numTMT']).reset_index(drop=True)\n",
    "    data = pd.merge(data, RT_mat,how='outer')\n",
    "    data['RT_Diff_fromUPL'] = data['RTavg_fromUPL']-data['RT in min']\n",
    "    data['RT_Diff_fromUPL_scaled'] = StandardScaler().fit_transform(data['RT_Diff_fromUPL'].values.reshape(len(data),1))\n",
    "    \n",
    "    #7. 统计蛋白的PSM以及unique peptides数量\n",
    "    data['ProtID_Pep'] = data['Master Protein Accessions'].map(str).str.cat([data['Upper_Seq']],sep='_')\n",
    "    data = cal_prot_psm(data,data,'Prot_totalPSMs')\n",
    "    data = cal_prot_psm(labeled_psms,data,'Prot_labeledPSMs')\n",
    "    data = cal_uni_pep(data,data,'Prot_uniquePeptides')\n",
    "    data = cal_uni_pep(labeled_psms,data,'Prot_labeledPeptides')\n",
    "    \n",
    "    #8. 在处理后的同位素数据选择paired为1或labeled为0的肽段，这样就保证了训练集中的阳性与阴性数据\n",
    "    #   随后重新计算RT_Diff_fromUPL_scaled，scoreDiff_scaled和numPSMs_scaled并用于模型训练\n",
    "    train_set_forPred['RT_Diff_fromUPL_scaled'] = StandardScaler().fit_transform(train_set_forPred['RT_Diff_fromUPL'].values.reshape(len(train_set_forPred),1))\n",
    "    train_set_forPred['scoreDiff_scaled'] = StandardScaler().fit_transform(train_set_forPred['scoreDiff'].values.reshape(len(train_set_forPred),1))\n",
    "    train_set_forPred['numPSMs_scaled'] = StandardScaler().fit_transform(train_set_forPred['numPSMs'].values.reshape(len(train_set_forPred),1))\n",
    "    use_name = ['numPSMs_scaled','scoreDiff_scaled','agreePSMs','RT_Diff_fromUPL_scaled']\n",
    "    lg_clf = LogisticRegression(solver='lbfgs',penalty='none',n_jobs=-1)\n",
    "    X = train_set_forPred[use_name].values.astype(np.float64)\n",
    "    y = train_set_forPred['labeled'].values.astype(np.float64)\n",
    "    lg_clf = lg_clf.fit(X,y)\n",
    "    \n",
    "    #9. 用训练好的模型预测TMT的数据\n",
    "    y_pre_train = lg_clf.predict_proba(X)[:,1]\n",
    "    y_pre_test = lg_clf.predict_proba(data[use_name].values.astype(np.float64))[:,1]\n",
    "    \n",
    "    #10. 总结训练集与测试集的结果，计算协方差矩阵，最后将测试集结果导出\n",
    "    train_out = train_set_forPred.copy()\n",
    "    train_out['lg_probs'] = y_pre_train\n",
    "    train_out.loc[train_out['lg_probs']>0.5,'lg_pred'] = 'Labeled'\n",
    "    train_out.loc[train_out['lg_probs']<=0.5,'lg_pred'] = 'Unlabeled'\n",
    "    train_out['model_set'] = 'train'\n",
    "    \n",
    "    train_y_pre = train_out['lg_pred'].values.copy()\n",
    "    train_y_pre[train_y_pre=='Labeled']=1\n",
    "    train_y_pre[train_y_pre=='Unlabeled']=0\n",
    "    train_y_pre = train_y_pre.astype(np.float64)\n",
    "    train_tn, train_fp, train_fn, train_tp = confusion_matrix(train_out['labeled'], train_y_pre).ravel()\n",
    "    \n",
    "    test_out = data.copy()\n",
    "    test_out['lg_probs'] = y_pre_test\n",
    "    test_out.loc[test_out['lg_probs']>0.5,'lg_pred'] = 'Labeled'\n",
    "    test_out.loc[test_out['lg_probs']<=0.5,'lg_pred'] = 'Unlabeled'\n",
    "    test_out['model_set'] = 'test'\n",
    "    \n",
    "    test_y_pre = test_out['lg_pred'].values.copy()\n",
    "    test_y_pre[test_y_pre=='Labeled']=1\n",
    "    test_y_pre[test_y_pre=='Unlabeled']=0\n",
    "    test_y_pre = test_y_pre.astype(np.float64)\n",
    "    test_tn, test_fp, test_fn, test_tp = confusion_matrix(test_out['labeled'], test_y_pre).ravel()\n",
    "    \n",
    "    test_out.loc[test_out['lg_probs']>=0.85,'label_confidence'] = 'High'\n",
    "    test_out.loc[(test_out['lg_probs']>=0.5)&(test_out['lg_probs']<0.85),'label_confidence'] = 'Medium'\n",
    "    test_out.loc[test_out['lg_probs']<0.5,'label_confidence'] = 'Low'\n",
    "\n",
    "    return test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78967e0e-d82e-4476-af41-f0f8afe3282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于TMT的PSM统计数据，在肽段层面上做进一步统计，具体过程如下：\n",
    "#1. 对每一个scanID选取Prot_totalPSMs或XCorr最高的肽段创建uniqueScan_DF\n",
    "#2. 根据uniqueScan_DF和PSM数据，统计每条标记肽段的光谱数和PSM数\n",
    "#3. 分别处理TMT10和16的数据，统计每条肽段的丰度的平均值\n",
    "#4. 根据TMT data输出的PSM数据，统计每条标记肽段的平均预测分数，XCorr，scoreDiff，numPSMs和RT_Diff_fromUPL\n",
    "#5. 统计每条标记肽段的标记位点，被标记的频率等信息\n",
    "\n",
    "def processPeps_TMT(processedPSMs, modID, plex='10plex'):\n",
    "\n",
    "    #1. 对每一个scanID选取Prot_totalPSMs或XCorr最高的肽段创建uniqueScan_DF \n",
    "    processedPSMs_sorted = processedPSMs.sort_values(by=['scanID','Prot_totalPSMs','XCorr'],ascending=[False,False,False]).reset_index(drop=True)\n",
    "    uniqueScan_DF = []\n",
    "    for uni_scan,table in processedPSMs_sorted.groupby(by=['scanID']):\n",
    "        table = table.sort_values(by=['Prot_totalPSMs','XCorr'],ascending=[False,False]).reset_index(drop=True)\n",
    "        uniqueScan_DF.append(table.iloc[0,:].values)\n",
    "    uniqueScan_DF = pd.DataFrame(uniqueScan_DF,columns=processedPSMs_sorted.columns)\n",
    "    uniqueScan_DF.to_excel(psm_path+'uniqueScanDF_TMTmerged_%s.xlsx'%datetime.datetime.now().strftime('%Y-%m-%d'),index=False)\n",
    "    \n",
    "    #2. 根据uniqueScan_DF和PSM数据，统计每条标记肽段的光谱数和PSM数\n",
    "    pepDF = pd.DataFrame()\n",
    "    pepDF['Unique_ID'] = uniqueScan_DF['pep_label'].unique()\n",
    "    pepDF = pd.merge(pepDF, uniqueScan_DF[['Master Protein Accessions','pep_label']],left_on=['Unique_ID'],right_on=['pep_label'],how='inner').drop_duplicates().iloc[:,:-1]\n",
    "    pepDF.columns = ['Unique_ID','Uniprot_ID']\n",
    "    spec_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(uniqueScan_DF['pep_label']).items()],columns=['Unique_ID','#_Spectra'])\n",
    "    pepDF = pd.merge(pepDF, spec_freq,how='outer')\n",
    "    psm_freq = pd.DataFrame([tuple((name,count)) for name,count in Counter(processedPSMs['pep_label']).items()],columns=['Unique_ID','#_PSMs'])\n",
    "    pepDF = pd.merge(pepDF, psm_freq,how='inner')\n",
    "    \n",
    "    #3. 分别处理TMT10和16的数据，统计每条肽段的丰度的平均值\n",
    "    if plex=='10plex':\n",
    "        use_col = [\"Abundance 126\", \"Abundance 127N\", \"Abundance 127C\", \"Abundance 128N\", \"Abundance 128C\", \n",
    "                   \"Abundance 129N\", \"Abundance 129C\", \"Abundance 130N\", \"Abundance 130C\", \"Abundance 131\", \"pep_label\"]\n",
    "    elif plex=='16plex':\n",
    "        use_col = [\"Abundance 126\", \"Abundance 127N\", \"Abundance 127C\", \"Abundance 128N\", \"Abundance 128C\", \n",
    "                   \"Abundance 129N\", \"Abundance 129C\", \"Abundance 130N\", \"Abundance 130C\", \"Abundance 131N\", \n",
    "                   \"Abundance 131C\", \"Abundance 132N\", \"Abundance 132C\", \"Abundance 133N\", \"Abundance 133C\",\n",
    "                   \"Abundance 134N\", \"pep_label\"]\n",
    "    tmtData = uniqueScan_DF.loc[:,use_col].copy()\n",
    "    tmtData = tmtData.replace(np.nan,1)\n",
    "    summedTMT = tmtData.groupby(by='pep_label').sum().reset_index(drop=False)\n",
    "    summedTMT = summedTMT.rename(columns={'pep_label':'Unique_ID'},inplace=True)\n",
    "    pepDF = pd.merge(pepDF, summedTMT,how='outer',on=['Unique_ID'])\n",
    "    \n",
    "    #4. 根据TMT data输出的PSM数据，统计每条标记肽段的平均预测分数，XCorr，scoreDiff，numPSMs和RT_Diff_fromUPL\n",
    "    feats_toAvg = ['lg_probs','XCorr','scoreDiff','numPSMs','RT_Diff_fromUPL']\n",
    "    averagedFeatures = processedPSMs.groupby(by='pep_label').mean()[feats_toAvg].reset_index(drop=False)\n",
    "    averagedFeatures.rename(columns={'pep_label':'Unique_ID'},inplace=True)\n",
    "    pepDF = pd.merge(pepDF, averagedFeatures,on='Unique_ID',how='inner')\n",
    "    max_lg = processedPSMs[['pep_label','lg_probs']].groupby(by='pep_label').max().reset_index(drop=False)\n",
    "    max_lg.columns = ['Unique_ID','max_lg_probs']\n",
    "    pepDF = pd.merge(pepDF, max_lg,on='Unique_ID',how='inner')\n",
    "    \n",
    "    #5. 统计每条标记肽段的标记位点，被标记的频率等信息\n",
    "    values = list(map(lambda x:extract_site(x,processedPSMs), pepDF['Unique_ID'].to_list()))\n",
    "    values = pd.DataFrame(values,columns=['Unique_ID','sites','aas','locs','site_psms'])\n",
    "    pepDF = pd.merge(pepDF, values,on='Unique_ID',how='inner')\n",
    "    temp = pepDF['Unique_ID'].str.split('_',expand=True)\n",
    "    temp.columns = ['PEPTIDE_SEQUENCE']+modID\n",
    "    pepDF = pd.concat([pepDF,temp],axis=1)\n",
    "    \n",
    "    return pepDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1329ca5-d463-4a30-9841-41a8f9cdb4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将来自Uniprot和AlphaFold的信息与处理好的肽段信息整合\n",
    "def matchUniFeatures(processedPeps, featureTab):\n",
    "    featureTab['Gene'] = featureTab['Gene Names'].str.split(' ',expand=True)[0]\n",
    "    for i in featureTab.index:\n",
    "        if pd.isna(featureTab.loc[i,'Gene']):\n",
    "            featureTab.loc[i,'Gene'] = featureTab.loc[i,'Entry']\n",
    "    \n",
    "    featureTab_reviewed = featureTab[featureTab['Reviewed']=='reviewed'].reset_index(drop=True)\n",
    "    featureTab_proteomics = featureTab[featureTab['Entry'].isin(processedPeps['Uniprot_ID'])].reset_index(drop=True)\n",
    "    \n",
    "    processedPeps = pd.merge(processedPeps, featureTab[['Entry','Gene']],\n",
    "                             left_on='Uniprot_ID',right_on='Entry',how='left')\n",
    "    reviewed_feature_cols = [\"Protein names\", \"Gene Names\", \"Active site\", \"Binding site\", \"Cofactor\", \"DNA binding\", \"Site\", \"PDB\", \"ChEMBL\", \"DrugBank\", \"Sequence\", \"Gene\", \"AlphaFoldDB\"]\n",
    "    processedPeps = pd.merge(processedPeps, featureTab_reviewed[reviewed_feature_cols],on='Gene',how='left').reset_index(drop=True)    \n",
    "    \n",
    "    for i in processedPeps.index:\n",
    "        pep_seq,seq = processedPeps.loc[i,['PEPTIDE_SEQUENCE','Sequence']].values\n",
    "        try: start = seq.find(pep_seq)+1\n",
    "        except:\n",
    "            processedPeps.loc[i,'Labeled Peptide'] = np.nan\n",
    "            processedPeps.loc[i,'TARG_PEPRANGE'] = np.nan\n",
    "        end = start+len(pep_seq)\n",
    "        peprange = '_'.join([str(start),str(end)])\n",
    "        targ_peprange = '_'.join([processedPeps.loc[i,'Uniprot_ID'],peprange])\n",
    "        processedPeps.loc[i,'Labeled Peptide'] = peprange\n",
    "        processedPeps.loc[i,'TARG_PEPRANGE'] = targ_peprange\n",
    "    processedPeps = processedPeps.replace(np.nan,'')\n",
    "    \n",
    "    return processedPeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab5f1f-1da6-4d33-a702-b933517aaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(processedPSMs,probe,model_set):\n",
    "    processedPSMs_ = processedPSMs[processedPSMs['model_set']==model_set].reset_index(drop=True)\n",
    "    y_data,y_pre = processedPSMs_['labeled'].values,processedPSMs_['lg_probs'].values\n",
    "    fpr,tpr,thre = roc_curve(np.float64(y_data),y_pre)\n",
    "    auc_score = roc_auc_score(y_data,y_pre)\n",
    "    \n",
    "    plt.plot(fpr,tpr,linewidth=2,label=probe+'_{:}_{:}'.format(model_set,round(auc_score,4)))\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=14,labelpad=10)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14,labelpad=10)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(fontsize=12,loc=4)\n",
    "    plt.title(probe,fontsize=12)\n",
    "    \n",
    "def pr_plot(processedPSMs,probe):\n",
    "    processedPSMs_ = processedPSMs[processedPSMs['model_set']=='test'].reset_index(drop=True)\n",
    "    y_test_data,y_test_pre = processedPSMs_['labeled'].values,processedPSMs_['lg_probs'].values\n",
    "    precision,recall,threshold = precision_recall_curve(np.float64(y_test_data),y_test_pre)\n",
    "    \n",
    "    plt.plot(threshold,precision[:-1],linewidth=2,label='Precision')\n",
    "    plt.plot(threshold,recall[:-1],linewidth=2,label='Recall')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('Threshold', fontsize=14,labelpad=5)\n",
    "    plt.ylabel('Score', fontsize=14,labelpad=5)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(fontsize=12,loc=4)\n",
    "    plt.title('{:}'.format(probe),fontsize=12)\n",
    "\n",
    "def metric_stat(table_dict,thre):\n",
    "    metric_data = []\n",
    "    for probe,processedPSMs in table_dict.items():\n",
    "        for model_set,table in processedPSMs.groupby(by='model_set'):\n",
    "            y_data,y_pre = table['labeled'].values,table['lg_probs'].values\n",
    "            re_y_pre = 1-y_pre\n",
    "            y_pre_array = np.c_[re_y_pre,y_pre]\n",
    "            mse = mean_squared_error(y_data, y_pre)\n",
    "            lg_pred = y_pre.copy()\n",
    "            lg_pred = ['Labeled' if i>thre else 'Unlabeled' for i in lg_pred]\n",
    "            loss = log_loss(lg_pred,y_pre_array)\n",
    "            metric_data.append(tuple((probe,model_set,mse,loss)))\n",
    "    metric_data = pd.DataFrame(metric_data,columns=['probe','model_set','mse','loss'])\n",
    "    return metric_data\n",
    "\n",
    "def metrics_plot(table_dict,thre):\n",
    "    metric_data = metric_stat(table_dict,thre)\n",
    "    \n",
    "    plt.figure(figsize=(4,4),dpi=100)\n",
    "    plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "    sns.scatterplot(data=metric_data,x='mse',y='loss',hue='model_set',s=60)\n",
    "    plt.xlabel('MSE',fontsize=14,labelpad=5)\n",
    "    plt.ylabel('Loose',fontsize=14,labelpad=5)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.title('Threshold = {:}'.format(thre),fontsize=16)\n",
    "    plt.xlim()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ecfc1-8152-4af7-90d9-6f1883d06304",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm_path = 'D:/All_for_paper/1. PhD Work Program/3. Research project/1. Dizco/Test files/'\n",
    "modID = ['-AC-Light','-AC-Heavy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcdb4c6-529f-498f-a3b6-214290671229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取同位素标记的PSM table\n",
    "for file_name in tqdm(listdir(psm_path+'isotope_data')):\n",
    "    psm_table_iso = pd.read_excel(psm_path+'isotope_data/'+file_name)\n",
    "    processedPSMs = processPSMs_isotope(psm_table_iso,modID,ptmRS=True)\n",
    "    processedPSMs.to_excel(psm_path+'isotope_processedPSMs/'+'processedPSMs_{:}_{:}.xlsx'.format(file_name.split('_')[2],datetime.datetime.now().strftime('%Y%m%d')),index=False)\n",
    "    processedPEPs = processPeps_isotope(processedPSMs)\n",
    "    processedPEPs.to_excel(psm_path+'isotope_processedPEPs/'+'processedPEPs_{:}_{:}.xlsx'.format(file_name.split('_')[2],datetime.datetime.now().strftime('%Y%m%d')),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc8197-4eb2-4b0b-884f-ea11160ad8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取同位素标记的处理后的PSM table，查看每一个的预测情况，并进行merge\n",
    "table_dict = {}\n",
    "merge_data = pd.DataFrame()\n",
    "for file_name in tqdm(listdir(psm_path+'isotope_processedPSMs')):\n",
    "    processedPSMs = pd.read_excel(psm_path+'isotope_processedPSMs/'+file_name)\n",
    "    probe = file_name.split('_')[1]\n",
    "    table_dict.setdefault(probe,processedPSMs)\n",
    "    processedPSMs_ = processedPSMs.copy()\n",
    "    processedPSMs_['probe'] = probe\n",
    "    if merge_data.empty: merge_data = processedPSMs_.copy()\n",
    "    else: merge_data = pd.concat([merge_data,processedPSMs_],axis=0)\n",
    "merge_data.to_csv(psm_path+'merge_isoTOP_PSM_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c3002-57a3-480a-827e-0279095c8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC plot的绘制\n",
    "fig,ax = plt.subplots(figsize=(12,12),dpi=600)\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "i = 1\n",
    "for probe,processedPSMs in table_dict.items():\n",
    "    plt.subplot(4,4,i)\n",
    "    roc_plot(processedPSMs,probe,'train')\n",
    "    roc_plot(processedPSMs,probe,'test')\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#P-R曲线绘制\n",
    "fig,ax = plt.subplots(figsize=(12,12),dpi=600)\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "i = 1\n",
    "for probe,processedPSMs in table_dict.items():\n",
    "    plt.subplot(4,4,i)\n",
    "    pr_plot(processedPSMs,probe)\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#model metrics\n",
    "metrics_plot(table_dict,thre=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3becd7-7096-46b8-a54e-07fa3eef55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#以delta score和PSM画散点图\n",
    "score_1 = merge_data[['scoreDiff_scaled','labeled']].copy()\n",
    "score_1.columns = ['Score','labeled']\n",
    "score_1['Name'] = 'ScoreDiff'\n",
    "score_2 = merge_data[['numPSMs_scaled','labeled']].copy()\n",
    "score_2.columns = ['Score','labeled']\n",
    "score_2['Name'] = 'numPSMs'\n",
    "score_table = pd.concat([score_1,score_2],axis=0)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(4,4),dpi=600)\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "ax=sns.boxplot(data=score_table, x='Name',y='Score',hue='labeled',\n",
    "            width=0.5,showfliers=False,)\n",
    "box_pairs = [(('ScoreDiff',1),('ScoreDiff',0)),\n",
    "             (('numPSMs',1),('numPSMs',0))]\n",
    "annot = Annotator(ax, data=score_table,x='Name',y='Score',hue='labeled',pairs=box_pairs)\n",
    "annot.configure(test='t-test_ind', text_format='star',line_height=0.03,line_width=1)\n",
    "annot.apply_and_annotate()\n",
    "plt.xlabel('',fontsize=14,labelpad=5)\n",
    "plt.ylabel('Score',fontsize=14,labelpad=5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles,['Unlabeled','Labeled'],fontsize=12,bbox_to_anchor=(0.50,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb65db9-2c8b-4eae-825c-3549f8dd16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计每个探针标记到的氨基酸的频率\n",
    "processedPEP = pd.read_csv(psm_path+'merge_isoTOP_PEP_data.csv')\n",
    "processedPEP_ = processedPEP[processedPEP['lg_probs']>0.5]\n",
    "processedPEP_ = processedPEP_[~processedPEP_['aas'].isna()].reset_index(drop=True)\n",
    "\n",
    "freq_data,avg_psm_data = pd.DataFrame(),pd.DataFrame()\n",
    "for probe,table in processedPEP_.groupby(by='probe'):\n",
    "    table['aas_list'] = table['aas'].str.split(';')\n",
    "    exploded_df = table.explode('aas_list')\n",
    "    table['psm_count'] = table['site_psms'].str.split(';')\n",
    "    exploded_df = pd.concat([exploded_df,table.explode('psm_count').iloc[:,-1]],axis=1)\n",
    "    exploded_df['psm_count'] = exploded_df['psm_count'].astype(np.float64)\n",
    "    \n",
    "    freq = exploded_df['aas_list'].value_counts().reset_index(drop=False)\n",
    "    freq.columns = ['amino acid',probe]\n",
    "    if freq_data.empty: freq_data = freq.copy()\n",
    "    else: freq_data = pd.merge(freq_data,freq,on=['amino acid'])\n",
    "    \n",
    "    avg_psm = exploded_df.groupby(by='aas_list').mean().iloc[:,-1].reset_index(drop=False)\n",
    "    avg_psm.columns = ['amino acid',probe]\n",
    "    if avg_psm_data.empty: avg_psm_data = avg_psm.copy()\n",
    "    else: avg_psm_data = pd.merge(avg_psm_data,avg_psm,on=['amino acid'])\n",
    "    \n",
    "\n",
    "freq_data.iloc[:,1:] = StandardScaler().fit_transform(freq_data.iloc[:,1:].values.reshape(len(freq_data),8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205e957-a1a9-453f-9eb3-eec437ea0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_plot(table):\n",
    "    plt.figure(figsize=(15,6),dpi=600)\n",
    "    plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "    ax=sns.heatmap(table.iloc[1:,:].values.astype(np.float64),square=True,\n",
    "                cbar_kws={\"shrink\": 0.8,\"label\": \"Z-score\"},cmap='vlag',\n",
    "                yticklabels=table.index[1:],xticklabels=table.iloc[0,:],\n",
    "                vmin=2,vmax=6)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16,rotation=0)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=16)\n",
    "    font = {'family':'Arial','size':16,}\n",
    "    cbar.set_label('Average PSM for per a.a',fontdict=font)\n",
    "    plt.xlabel('Amino acid',fontsize=18,labelpad=5)\n",
    "    plt.ylabel('Probes',fontsize=18,labelpad=5)\n",
    "    plt.show()\n",
    "\n",
    "heatmap_plot(freq_data.T)\n",
    "heatmap_plot(avg_psm_data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca0a63-c7fc-4097-a5ae-a8b68c577c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
