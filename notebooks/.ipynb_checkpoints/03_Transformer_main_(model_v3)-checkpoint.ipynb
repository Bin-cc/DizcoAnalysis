{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734785a5-b8c9-4b44-a4b6-366360b7bddd",
   "metadata": {},
   "source": [
    "##### 此部分代码仅使用简单的单层transformer encoder对蛋白embedding进行编译，不涉及额外信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041e2bf-f017-4cec-8f0e-6ca3c2b21b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('E:/Proteomics/PhD_script/1. Dizco/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from DataTransform import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from EarlyStopping import EarlyStopping\n",
    "from models import FFFTrans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,precision_score,recall_score,f1_score,accuracy_score,matthews_corrcoef,average_precision_score,brier_score_loss,auc,precision_recall_curve\n",
    "from statannotations.Annotator import Annotator\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c962f-cc04-45e2-9b51-f936db91e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResLabel(table,thre=0.85):\n",
    "    label_table = table[table['lg_probs']>thre]\n",
    "    label_table = label_table[~label_table['label_site'].isna()]\n",
    "    unlabel_table = table[table['lg_probs']<=thre]\n",
    "    \n",
    "    labeledPEP = ParseRes(label_table,state='labeled')\n",
    "    unlabeledPEP = ParseRes(unlabel_table,state='unlabeled')\n",
    "    res_table = pd.concat([labeledPEP,unlabeledPEP],axis=0)\n",
    "    res_table = res_table.sort_values(by='label',ascending=False).reset_index(drop=True)\n",
    "    res_table = res_table.drop_duplicates(subset=['Accession','res_site']).reset_index(drop=True)\n",
    "    \n",
    "    prot_lt = list(res_table['Accession'].unique())\n",
    "    prot_label = {}\n",
    "    for prot in prot_lt:\n",
    "        seq = uniprot_infor[uniprot_infor['Entry']==prot].iloc[0,-1]\n",
    "        prot_dict = {f'{p}{i+1}':0 for i,p in enumerate(seq)}\n",
    "        prot_label.setdefault(prot,prot_dict)\n",
    "    \n",
    "    for prot,table in res_table.groupby(by='Accession'):\n",
    "        for site,label in zip(table['res_site'].to_list(),table['label'].to_list()):\n",
    "            prot_label[prot][site] = label\n",
    "\n",
    "    return prot_label\n",
    "    \n",
    "def ParseRes(data,state='labeled'):\n",
    "    pep_label_result = pd.DataFrame()\n",
    "    for (prot,pep),table in data.groupby(by=['Master Protein Accessions','Upper_Seq']):\n",
    "        try: seq = uniprot_infor[uniprot_infor['Entry']==prot].iloc[0,-1]\n",
    "        except: continue\n",
    "\n",
    "        start = seq.find(pep)+1\n",
    "        label_site = list(table['label_site'].unique())\n",
    "        pep_label = []\n",
    "        for i,p in enumerate(pep):\n",
    "            if state == 'labeled':\n",
    "                if f'{p}{i+1}' in label_site:\n",
    "                    pep_label.append(tuple((prot,f'{p}{start+i}',1)))\n",
    "                else: pep_label.append(tuple((prot,f'{p}{start+i}',0)))\n",
    "            elif state == 'unlabeled' : pep_label.append(tuple((prot,f'{p}{start+i}',0)))\n",
    "        pep_label = pd.DataFrame(pep_label,columns=['Accession','res_site','label'])\n",
    "        pep_label_result = pd.concat([pep_label_result,pep_label],axis=0)\n",
    "    pep_label_result = pep_label_result.sort_values(by='label',ascending=False).reset_index(drop=True)\n",
    "   \n",
    "    return pep_label_result.drop_duplicates(subset=['Accession','res_site'])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    probe_emd, prot_emd, labels, att_mask = zip(*batch)\n",
    "    batch_probe_emd = torch.stack(probe_emd)\n",
    "    batch_prot_emd = torch.stack(prot_emd)\n",
    "    batch_labels = torch.stack(labels)\n",
    "    batch_att_mask = torch.stack(att_mask)\n",
    "    return batch_probe_emd, batch_prot_emd, batch_labels, batch_att_mask\n",
    "\n",
    "def model_train(model,train_set,val_set,save_best_model=True,model_path=None,save_path=None,earlyStop=True,epochs=100,lr=0.0001):\n",
    "    if save_path is not None: early_stopping = EarlyStopping(save_path)\n",
    "    else: earlyStop = False\n",
    "    metrics_name = ['train_loss','val_loss','acc','precision','recall','f1','ap','bsl','mcc','auc_score','prc_score']\n",
    "    #定义损失函数计算方法，定义优化器\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-4)\n",
    "    scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=lr/10, max_lr=lr*10,\n",
    "                                      cycle_momentum=False,step_size_up=len(train_set))\n",
    "    \n",
    "    metrics_result = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_num = 0\n",
    "        \n",
    "        for probe_emd,prot_emd,labels,att_mask in train_set:\n",
    "            probe_emd,prot_emd,labels,att_mask = probe_emd.to(device), prot_emd.to(device), labels.to(device), att_mask.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(probe_emd,prot_emd,att_mask)\n",
    "            mask = ~att_mask.bool()\n",
    "            output_masked = output[mask]\n",
    "            labels_masked = labels[mask]\n",
    "            total_num += len(labels_masked)\n",
    "            loss = criterion(output_masked.squeeze(), labels_masked.float())\n",
    "            total_loss += loss.item()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        train_loss = total_loss / total_num\n",
    "        eval_matrics = model_eval(model,val_set,criterion)\n",
    "        metrics_result.append(tuple((train_loss,))+eval_matrics)\n",
    "    \n",
    "        if earlyStop:\n",
    "            early_stopping(eval_matrics[0], model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                return pd.DataFrame(metrics_result,columns=metrics_name)\n",
    "            break\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_mcc = eval_matrics[7]\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_metrics = tuple((epoch,train_loss))+eval_matrics\n",
    "        else:\n",
    "            if eval_matrics[7] > best_mcc:\n",
    "                best_mcc = eval_matrics[7]\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_metrics = tuple((epoch,train_loss))+eval_matrics\n",
    "        \n",
    "    if save_best_model:\n",
    "        torch.save(best_model.state_dict(),model_path+'best_model.pth')\n",
    "        print('The metrics of best model are:\\n')\n",
    "        print(f'epoch: {best_metrics[0]}, train_loss: {best_metrics[1]}, val_loss: {best_metrics[2]}\\n')\n",
    "        print(f'acc: {best_metrics[3]}, precision: {best_metrics[4]}, recall: {best_metrics[5]}\\n')\n",
    "        print(f'f1: {best_metrics[6]}, ap: {best_metrics[7]}, bsl: {best_metrics[8]}\\n')\n",
    "        print(f'mcc: {best_metrics[9]}, AUC: {best_metrics[10]}, PRC: {best_metrics[11]}')\n",
    "        \n",
    "    return pd.DataFrame(metrics_result,columns=metrics_name)\n",
    "\n",
    "\n",
    "def model_eval(model,val_set,criterion,thre=0.5):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true,y_pred,y_prob = [],[],[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for probe_emd,prot_emd,labels,att_mask in val_set:\n",
    "            probe_emd,prot_emd,labels,att_mask = probe_emd.to(device), prot_emd.to(device), labels.to(device), att_mask.to(device)\n",
    "            output = model(probe_emd,prot_emd,att_mask)\n",
    "            mask = ~att_mask.bool()\n",
    "            output_masked = output[mask]\n",
    "            labels_masked = labels[mask]\n",
    "            \n",
    "            prob = output_masked.squeeze()\n",
    "            loss = criterion(prob, labels_masked.float())\n",
    "            total_loss += loss.item()\n",
    "            pred = (prob >= thre).int()\n",
    "            y_true.extend(labels_masked.tolist())\n",
    "            y_pred.extend(pred.tolist())\n",
    "            y_prob.extend(prob.tolist())\n",
    "    \n",
    "        val_loss = total_loss/len(val_set)\n",
    "        eval_matrics = metrics_calculation(y_true,y_pred,y_prob)\n",
    "        \n",
    "        return tuple((val_loss,))+eval_matrics\n",
    "    \n",
    "def metrics_calculation(y_true,y_pred,y_prob):\n",
    "    y_true, y_pred, y_prob = np.float64(y_true), np.float64(y_pred), np.float64(y_prob)\n",
    "\n",
    "    auc_score = roc_auc_score(y_true,y_prob)\n",
    "    acc = accuracy_score(y_true,y_pred)\n",
    "    precision = precision_score(y_true,y_pred,average=None)[1]\n",
    "    recall = recall_score(y_true,y_pred)\n",
    "    f1 = f1_score(y_true,y_pred)\n",
    "    mcc = matthews_corrcoef(y_true,y_pred)\n",
    "    ap = average_precision_score(y_true,y_prob,average=None)\n",
    "    bsl = brier_score_loss(y_true,y_prob)\n",
    "    tpr,fpr,_ = precision_recall_curve(y_true,y_prob)\n",
    "    prc_score = auc(fpr,tpr)\n",
    "    \n",
    "    return tuple((acc,precision,recall,f1,ap,bsl,mcc,auc_score,prc_score))\n",
    "\n",
    "def metrics_plots(metrics,thre_col='mcc'):\n",
    "    best_epoch = metrics.sort_values(by=thre_col,ascending=False).index[0]\n",
    "    \n",
    "    #评估指标在每个epoch中的表现\n",
    "    plt.figure(figsize=(6,4),dpi=100)\n",
    "    for i in range(metrics.shape[1]):\n",
    "        if i < 2: continue\n",
    "        plt.plot(metrics.index,metrics.iloc[:,i],label=metrics.columns[i])\n",
    "    plt.axvline(x=best_epoch,color='black',linestyle='--')\n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    plt.xlabel('Epoch',fontsize=12)\n",
    "    plt.ylabel('Score',fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    #每个epoch中损失情况\n",
    "    plt.figure(figsize=(6,4),dpi=100)\n",
    "    for i in range(metrics.shape[1]):\n",
    "        if i >= 2: continue\n",
    "        plt.plot(metrics.index,metrics.iloc[:,i],label=metrics.columns[i])\n",
    "    plt.axvline(x=best_epoch,color='black',linestyle='--')\n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    plt.xlabel('Epoch',fontsize=12)\n",
    "    plt.ylabel('Loss',fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "def model_test(model,test_set):\n",
    "    model.eval()\n",
    "    out_lt, label_lt = np.array([]), np.array([])\n",
    "\n",
    "    for probe_emd,prot_emd,labels,att_mask in val_set:\n",
    "        probe_emd,prot_emd,labels,att_mask = probe_emd.to(device), prot_emd.to(device), labels.to(device), att_mask.to(device)\n",
    "        output = model(probe_emd,prot_emd,att_mask)\n",
    "        mask = ~att_mask.bool()\n",
    "        output_masked = output[mask]\n",
    "        labels_masked = labels[mask]\n",
    "        out_lt = np.append(out_lt, output_masked.tolist())\n",
    "        label_lt = np.append(label_lt, labels_masked.tolist())\n",
    "        \n",
    "    return out_lt,label_lt\n",
    "\n",
    "\n",
    "path = 'D:/All_for_paper/1. PhD Work Program/3. Research project/1. Dizco/'\n",
    "merge_PSM = pd.read_csv(f'{path}Test files/merge_isoTOP_PSM_data.csv')\n",
    "uniprot_infor = pd.read_csv(f'{path}Test files/uniprotkb_human_AND_reviewed_true_AND_m_2024_09_12.tsv',sep='\\t')\n",
    "uniprot_infor['Gene Names'] = uniprot_infor['Gene Names'].str.split(' ',expand=True)[0]\n",
    "\n",
    "#1. 整合数据\n",
    "dataset,prot_labels = [],[]\n",
    "for probe,table in tqdm(merge_PSM.groupby(by='probe')):\n",
    "    if probe == 'AJ5': continue\n",
    "    prot_label = ResLabel(table,thre=0.85)\n",
    "    for prot,prot_infor in prot_label.items():\n",
    "        seq,label = [],[]\n",
    "        for res,l in prot_infor.items():\n",
    "            seq.append(res[0])\n",
    "            label.append(l)\n",
    "        dataset.append(tuple((probe,''.join(seq),label)))\n",
    "        if 1 in label: prot_labels.append(1)\n",
    "        else: prot_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc97527-08d3-479e-be21-97f738614d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of identified protein length\n",
    "prot_list = merge_PSM['Master Protein Accessions'].unique()\n",
    "prot_len = [uniprot_infor[uniprot_infor['Entry']==prot].iloc[0,7] for prot in prot_list if not uniprot_infor[uniprot_infor['Entry']==prot].empty]\n",
    "plt.figure(figsize=(1,3))\n",
    "sns.boxplot(prot_len,width=0.5,showfliers=False)\n",
    "plt.xlabel('Identified\\nproteins',fontsize=12)\n",
    "plt.ylabel('Protein length',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de659a0-b368-4539-bd86-23bc844239f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 划分数据集\n",
    "tv_index, test_index = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42,\n",
    "                                        shuffle=True, stratify=prot_labels)\n",
    "tv_set, test_set = [dataset[i] for i in tv_index], [dataset[i] for i in test_index]\n",
    "train_set, val_set = train_test_split(tv_set, test_size=1/9, random_state=42,\n",
    "                                      shuffle=True, stratify=np.array(prot_labels)[tv_index])\n",
    "train_set = CustomDataset(train_set)\n",
    "val_set = CustomDataset(val_set)\n",
    "test_set = CustomDataset(test_set)\n",
    "train_set = DataLoader(train_set, shuffle=True, batch_size=8, drop_last=True, collate_fn=collate_fn)\n",
    "val_set = DataLoader(val_set, shuffle=False, batch_size=8, drop_last=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5fc43-46f1-40af-8e5f-b2c11acab8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 模型训练与评估\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = 'E:/Proteomics/PhD_script/1. Dizco/'\n",
    "\n",
    "fff = FFFTrans().to(device)\n",
    "metrics_result = model_train(fff,train_set,val_set,model_path=model_path,lr=0.0001)\n",
    "metrics_plots(metrics_result,thre_col='mcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4f1cf-b8ee-45be-9a91-cb24b364372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 测试集评估\n",
    "fff.load_state_dict(torch.load(f'{model_path}best_model.pth'))\n",
    "\n",
    "test_output,test_labels = model_test(fff,test_set)\n",
    "test_data = pd.DataFrame([test_output,test_labels]).T\n",
    "test_data.columns = ['prob','label']\n",
    "test_data['model'] = 'Transformer'\n",
    "\n",
    "plt.figure(figsize=(2,4),dpi=100)\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "ax=sns.boxplot(data=test_data,x='model',y='prob',hue='label',\n",
    "            width=0.5,showfliers=False)\n",
    "box_pairs = [(('Transformer',1),('Transformer',0))]\n",
    "annot = Annotator(ax, data=test_data,x='model',y='prob',hue='label',pairs=box_pairs)\n",
    "annot.configure(test='t-test_ind', text_format='star',line_height=0.03,line_width=1)\n",
    "annot.apply_and_annotate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c177a7-ca9c-4272-a738-08cb21cee63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
